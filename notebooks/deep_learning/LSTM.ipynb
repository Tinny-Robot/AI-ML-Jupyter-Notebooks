{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"index.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = [\"Creditability\"])\n",
    "y = df['Creditability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=sc.fit_transform(X_train)\n",
    "test_x=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_x\n",
    "X_test = test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='relu', input_shape = X_train[0].shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 32)                4352      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,569\n",
      "Trainable params: 5,505\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.0001), loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 670 samples, validate on 330 samples\n",
      "Epoch 1/2\n",
      "670/670 [==============================] - 3s 5ms/sample - loss: 0.7176 - accuracy: 0.5328 - val_loss: 0.6907 - val_accuracy: 0.5758\n",
      "Epoch 2/2\n",
      "670/670 [==============================] - 0s 498us/sample - loss: 0.7194 - accuracy: 0.5224 - val_loss: 0.6890 - val_accuracy: 0.6576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f86c0643cf8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49951282],\n",
       "       [0.5059244 ],\n",
       "       [0.51092327],\n",
       "       [0.50444627],\n",
       "       [0.49722722],\n",
       "       [0.50104135],\n",
       "       [0.5000357 ],\n",
       "       [0.50875443],\n",
       "       [0.5060254 ],\n",
       "       [0.5025681 ],\n",
       "       [0.50752604],\n",
       "       [0.5007153 ],\n",
       "       [0.5051992 ],\n",
       "       [0.50780046],\n",
       "       [0.51294774],\n",
       "       [0.50932795],\n",
       "       [0.5103603 ],\n",
       "       [0.51022565],\n",
       "       [0.5017758 ],\n",
       "       [0.50342315],\n",
       "       [0.50542265],\n",
       "       [0.49562234],\n",
       "       [0.5075791 ],\n",
       "       [0.5090464 ],\n",
       "       [0.5042642 ],\n",
       "       [0.5064531 ],\n",
       "       [0.51089877],\n",
       "       [0.5054694 ],\n",
       "       [0.49928054],\n",
       "       [0.5051818 ],\n",
       "       [0.5003625 ],\n",
       "       [0.50163394],\n",
       "       [0.50169617],\n",
       "       [0.5082048 ],\n",
       "       [0.5115789 ],\n",
       "       [0.50754166],\n",
       "       [0.5143276 ],\n",
       "       [0.49782434],\n",
       "       [0.50907886],\n",
       "       [0.5076088 ],\n",
       "       [0.50484854],\n",
       "       [0.5118314 ],\n",
       "       [0.5114018 ],\n",
       "       [0.5083698 ],\n",
       "       [0.5066297 ],\n",
       "       [0.50645715],\n",
       "       [0.50817883],\n",
       "       [0.50953776],\n",
       "       [0.4993485 ],\n",
       "       [0.50340736],\n",
       "       [0.5089311 ],\n",
       "       [0.5014691 ],\n",
       "       [0.50471103],\n",
       "       [0.5066039 ],\n",
       "       [0.5080731 ],\n",
       "       [0.5067282 ],\n",
       "       [0.49637136],\n",
       "       [0.5058775 ],\n",
       "       [0.50878865],\n",
       "       [0.5034506 ],\n",
       "       [0.5102989 ],\n",
       "       [0.49636096],\n",
       "       [0.51051664],\n",
       "       [0.5023349 ],\n",
       "       [0.50708616],\n",
       "       [0.5112699 ],\n",
       "       [0.50864476],\n",
       "       [0.5103585 ],\n",
       "       [0.5016882 ],\n",
       "       [0.5073175 ],\n",
       "       [0.50367665],\n",
       "       [0.50488913],\n",
       "       [0.5087933 ],\n",
       "       [0.5099644 ],\n",
       "       [0.5067342 ],\n",
       "       [0.50837284],\n",
       "       [0.50545007],\n",
       "       [0.50136214],\n",
       "       [0.5101836 ],\n",
       "       [0.5097068 ],\n",
       "       [0.51156175],\n",
       "       [0.5023691 ],\n",
       "       [0.50820684],\n",
       "       [0.5038787 ],\n",
       "       [0.50660604],\n",
       "       [0.5088231 ],\n",
       "       [0.50064844],\n",
       "       [0.5092856 ],\n",
       "       [0.50964826],\n",
       "       [0.50626165],\n",
       "       [0.49888438],\n",
       "       [0.50255126],\n",
       "       [0.5089324 ],\n",
       "       [0.5083563 ],\n",
       "       [0.5063013 ],\n",
       "       [0.5077841 ],\n",
       "       [0.5037055 ],\n",
       "       [0.5052837 ],\n",
       "       [0.49718663],\n",
       "       [0.5046457 ],\n",
       "       [0.4981749 ],\n",
       "       [0.49828398],\n",
       "       [0.5100388 ],\n",
       "       [0.509444  ],\n",
       "       [0.50979304],\n",
       "       [0.49938774],\n",
       "       [0.50923604],\n",
       "       [0.50667876],\n",
       "       [0.5083396 ],\n",
       "       [0.50883955],\n",
       "       [0.4992439 ],\n",
       "       [0.5034518 ],\n",
       "       [0.49972013],\n",
       "       [0.5051442 ],\n",
       "       [0.5017308 ],\n",
       "       [0.5094211 ],\n",
       "       [0.5066628 ],\n",
       "       [0.5051575 ],\n",
       "       [0.50930214],\n",
       "       [0.5068015 ],\n",
       "       [0.5054764 ],\n",
       "       [0.50322336],\n",
       "       [0.5100048 ],\n",
       "       [0.5112855 ],\n",
       "       [0.5126378 ],\n",
       "       [0.5044914 ],\n",
       "       [0.50853664],\n",
       "       [0.5079399 ],\n",
       "       [0.504086  ],\n",
       "       [0.5081378 ],\n",
       "       [0.5082056 ],\n",
       "       [0.49588573],\n",
       "       [0.50665563],\n",
       "       [0.5110008 ],\n",
       "       [0.50715613],\n",
       "       [0.49967226],\n",
       "       [0.5021969 ],\n",
       "       [0.50751483],\n",
       "       [0.5070226 ],\n",
       "       [0.50647837],\n",
       "       [0.50411236],\n",
       "       [0.5062671 ],\n",
       "       [0.5029019 ],\n",
       "       [0.51040083],\n",
       "       [0.5081014 ],\n",
       "       [0.5069166 ],\n",
       "       [0.50414646],\n",
       "       [0.50947607],\n",
       "       [0.5082269 ],\n",
       "       [0.5085294 ],\n",
       "       [0.5073247 ],\n",
       "       [0.5082499 ],\n",
       "       [0.5013436 ],\n",
       "       [0.51129   ],\n",
       "       [0.5089762 ],\n",
       "       [0.50465953],\n",
       "       [0.50763875],\n",
       "       [0.5082254 ],\n",
       "       [0.50330824],\n",
       "       [0.5045865 ],\n",
       "       [0.5061069 ],\n",
       "       [0.50860775],\n",
       "       [0.5070191 ],\n",
       "       [0.5065735 ],\n",
       "       [0.499753  ],\n",
       "       [0.51047236],\n",
       "       [0.5129754 ],\n",
       "       [0.51064444],\n",
       "       [0.5020866 ],\n",
       "       [0.49892476],\n",
       "       [0.51043713],\n",
       "       [0.5016924 ],\n",
       "       [0.5047477 ],\n",
       "       [0.50974405],\n",
       "       [0.49946907],\n",
       "       [0.5106211 ],\n",
       "       [0.4995141 ],\n",
       "       [0.509055  ],\n",
       "       [0.5102518 ],\n",
       "       [0.50806594],\n",
       "       [0.50723934],\n",
       "       [0.5102157 ],\n",
       "       [0.49939686],\n",
       "       [0.5106121 ],\n",
       "       [0.5096451 ],\n",
       "       [0.5094768 ],\n",
       "       [0.50265294],\n",
       "       [0.506138  ],\n",
       "       [0.508791  ],\n",
       "       [0.5058977 ],\n",
       "       [0.50592226],\n",
       "       [0.50910294],\n",
       "       [0.50365764],\n",
       "       [0.50979155],\n",
       "       [0.5028059 ],\n",
       "       [0.50623715],\n",
       "       [0.5053961 ],\n",
       "       [0.49768808],\n",
       "       [0.50918406],\n",
       "       [0.5013002 ],\n",
       "       [0.5042736 ],\n",
       "       [0.5041725 ],\n",
       "       [0.5011154 ],\n",
       "       [0.5059771 ],\n",
       "       [0.50372875],\n",
       "       [0.50645566],\n",
       "       [0.49910396],\n",
       "       [0.49960244],\n",
       "       [0.50375724],\n",
       "       [0.5094527 ],\n",
       "       [0.50740725],\n",
       "       [0.50923663],\n",
       "       [0.51069516],\n",
       "       [0.50232494],\n",
       "       [0.5057257 ],\n",
       "       [0.5068723 ],\n",
       "       [0.5086795 ],\n",
       "       [0.50792724],\n",
       "       [0.5103685 ],\n",
       "       [0.5078713 ],\n",
       "       [0.5114532 ],\n",
       "       [0.50122464],\n",
       "       [0.5095844 ],\n",
       "       [0.50282323],\n",
       "       [0.510191  ],\n",
       "       [0.51273066],\n",
       "       [0.5048797 ],\n",
       "       [0.5044309 ],\n",
       "       [0.5101955 ],\n",
       "       [0.5060909 ],\n",
       "       [0.5011564 ],\n",
       "       [0.5050354 ],\n",
       "       [0.5098326 ],\n",
       "       [0.5033906 ],\n",
       "       [0.50829977],\n",
       "       [0.50161916],\n",
       "       [0.50905484],\n",
       "       [0.5099664 ],\n",
       "       [0.50827354],\n",
       "       [0.5098233 ],\n",
       "       [0.5042132 ],\n",
       "       [0.504282  ],\n",
       "       [0.510084  ],\n",
       "       [0.5046218 ],\n",
       "       [0.5097743 ],\n",
       "       [0.5066063 ],\n",
       "       [0.50429374],\n",
       "       [0.5020264 ],\n",
       "       [0.50616044],\n",
       "       [0.5045933 ],\n",
       "       [0.50170344],\n",
       "       [0.4983276 ],\n",
       "       [0.51229435],\n",
       "       [0.50255704],\n",
       "       [0.5092947 ],\n",
       "       [0.5040266 ],\n",
       "       [0.5051545 ],\n",
       "       [0.51009756],\n",
       "       [0.5084809 ],\n",
       "       [0.5041223 ],\n",
       "       [0.4962954 ],\n",
       "       [0.5006149 ],\n",
       "       [0.5027519 ],\n",
       "       [0.50871104],\n",
       "       [0.50481653],\n",
       "       [0.5068357 ],\n",
       "       [0.50968087],\n",
       "       [0.5100914 ],\n",
       "       [0.5005314 ],\n",
       "       [0.5121999 ],\n",
       "       [0.50864947],\n",
       "       [0.5011311 ],\n",
       "       [0.5035939 ],\n",
       "       [0.5031296 ],\n",
       "       [0.5076793 ],\n",
       "       [0.5143737 ],\n",
       "       [0.49524248],\n",
       "       [0.51065624],\n",
       "       [0.50218475],\n",
       "       [0.51009065],\n",
       "       [0.50386494],\n",
       "       [0.5101669 ],\n",
       "       [0.5076261 ],\n",
       "       [0.50622654],\n",
       "       [0.50604236],\n",
       "       [0.49713472],\n",
       "       [0.50166017],\n",
       "       [0.50972927],\n",
       "       [0.50930023],\n",
       "       [0.5113481 ],\n",
       "       [0.5128438 ],\n",
       "       [0.50905526],\n",
       "       [0.5014495 ],\n",
       "       [0.515424  ],\n",
       "       [0.5068319 ],\n",
       "       [0.50944376],\n",
       "       [0.5037246 ],\n",
       "       [0.5086827 ],\n",
       "       [0.50447863],\n",
       "       [0.50945705],\n",
       "       [0.4972667 ],\n",
       "       [0.5045916 ],\n",
       "       [0.50725484],\n",
       "       [0.5023409 ],\n",
       "       [0.5075863 ],\n",
       "       [0.5075937 ],\n",
       "       [0.5007575 ],\n",
       "       [0.5038117 ],\n",
       "       [0.50421965],\n",
       "       [0.50812817],\n",
       "       [0.50688565],\n",
       "       [0.50673765],\n",
       "       [0.50871545],\n",
       "       [0.50581783],\n",
       "       [0.49939638],\n",
       "       [0.499424  ],\n",
       "       [0.51184905],\n",
       "       [0.5020542 ],\n",
       "       [0.5010477 ],\n",
       "       [0.50605077],\n",
       "       [0.50720924],\n",
       "       [0.5029425 ],\n",
       "       [0.5081021 ],\n",
       "       [0.495906  ],\n",
       "       [0.505363  ],\n",
       "       [0.50162005],\n",
       "       [0.50013155],\n",
       "       [0.50740516],\n",
       "       [0.50918734],\n",
       "       [0.5090782 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = (Y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_lstm = confusion_matrix(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.imshow(cm_lstm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('LSTM')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm_lstm[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.7003367003367004\n",
      "recall = 0.896551724137931\n",
      "accuracy = 0.6575757575757576\n",
      "F1 Score = 0.7863894139886579\n"
     ]
    }
   ],
   "source": [
    "precision_ann = precision_score(y_test, Y_pred)\n",
    "print(\"precision = \"+str(precision_ann))\n",
    "recall_ann = recall_score(y_test, Y_pred)\n",
    "print(\"recall = \"+ str(recall_ann))\n",
    "accuracy_ann = accuracy_score(y_test, Y_pred)\n",
    "print(\"accuracy = \"+ str(accuracy_ann))\n",
    "F1_score_ann = f1_score(y_test, Y_pred)\n",
    "print(\"F1 Score = \"+ str(F1_score_ann))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = cm_lstm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity =0.09183673469387756\n"
     ]
    }
   ],
   "source": [
    "specificity = (tn)/(tn+fp)\n",
    "print(\"specificity =\"+ str(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"index.csv\")\n",
    "\n",
    "df.head()\n",
    "\n",
    "X = df.drop(columns = [\"Creditability\"])\n",
    "y = df['Creditability']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "\n",
    "train_x=sc.fit_transform(X_train)\n",
    "test_x=sc.fit_transform(X_test)\n",
    "\n",
    "X_train = train_x\n",
    "X_test = test_x\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "y_train\n",
    "\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "y_test\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "print(tf.__version__)\n",
    "\n",
    "#BatchNormalization() -> DIVIDE INTO MINI BATCHED AND STANDARDISES FOR TRAINING\n",
    "#DROPOUT -> DROPPING THE NUMBER OF % OF NEURONS WHICH ARE NOT UPDATING THERE WEIGHTS DURING TRAINING\n",
    "#FLATTEN -> FULLY CONNECTED LAYER \n",
    "epochs = 50\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, 2, activation='relu', input_shape = X_train[0].shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(64, 2, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "Y_pred = (Y_pred > 0.5)\n",
    "\n",
    "Y_pred\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_pred,y_test)\n",
    "\n",
    "cm_cnn = confusion_matrix(y_test, Y_pred)\n",
    "\n",
    "precision_ann = precision_score(y_test, Y_pred)\n",
    "print(\"precision = \"+str(precision_ann))\n",
    "recall_ann = recall_score(y_test, Y_pred)\n",
    "print(\"recall = \"+ str(recall_ann))\n",
    "accuracy_ann = accuracy_score(y_test, Y_pred)\n",
    "print(\"accuracy = \"+ str(accuracy_ann))\n",
    "F1_score_ann = f1_score(y_test, Y_pred)\n",
    "print(\"F1 Score = \"+ str(F1_score_ann))\n",
    "\n",
    "tn, fp, fn, tp = cm_cnn.ravel()\n",
    "\n",
    "specificity = (tn)/(tn+fp)\n",
    "print(\"specificity =\"+ str(specificity))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
